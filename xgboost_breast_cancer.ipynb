{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Prediction with XGBoost\n",
    "_**Using Gradient Boosted Trees to Predict breast cancer with features derived from breast mass images**_\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Hosting)\n",
    "  1. [Evaluate](#Evaluate)\n",
    "1. [Extensions](#Extensions)\n",
    "  1. [Hyperparameter Optimization](#Hyperparameter-Optimization)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "This notebook illustrates the use of SageMaker's built-in XGBoost algorithm for binary classification.\n",
    "XGBoost uses decision trees to build a predictive model.\n",
    "\n",
    "Also demonstrated is Hyperparameter optimization as well as using the best model from HPO to instantiate a new endpoint\n",
    "\n",
    "### Why XGBoost and not Logistic Regression?\n",
    "\n",
    "Whilst logistic regression is often used for classification exercises, it has some drawbacks. For example, additional feature engineering is required to deal with non-linear features.\n",
    "\n",
    "XGBoost (an implementation of Gradient Boosted Trees) offers several benefits including naturally accounting for non-linear relationships between features and the target variable, as well as accommodating complex interactions between features.\n",
    "Decision Tree algorithms such as XGBoost also have the added benefit of being able to deal with missing values in both the training dataset as well as unseen samples that are being used for inference.\n",
    "\n",
    "Amazon SageMaker provides an XGBoost container that we can use to train in a managed, distributed setting, and then host as a real-time prediction endpoint\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.t2.medium notebook instance._\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The SageMaker role arn used to give learning and hosting access to your data. The snippet below will use the same role used by your SageMaker notebook instance. If you wish to use a different role, specify the full ARN of a role with the SageMakerFullAccess policy attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "bucket = 'Your-S3-Bucket'\n",
    "prefix = 'sagemaker/DEMO-xgboost-churn'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the Python libraries we'll need for the remainder of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "For this illustration, we have taken an example for breast cancer prediction using UCI'S breast cancer diagnostic data set available at https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29. The data set is also available on Kaggle at https://www.kaggle.com/uciml/breast-cancer-wisconsin-data. The purpose here is to use this data set to build a predictve model of whether a breast mass image indicates benign or malignant tumor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\n",
    "    \n",
    "# You can find out all the details of this dataset here: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "\n",
    "#Let's download the data and save it in the local folder with the name data.csv and take a look at it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we downloaded does not have column headings; however this information is available at the source\n",
    "\n",
    "More information about this dataset can be found here: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "Sample images used in this dataset can be seen here: ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer_images\n",
    "\n",
    "- `id`: ID number\n",
    "- `diagnosis`: The diagnosis of breast tissues (M = malignant, B = benign)\n",
    "- `radius_mean`: mean of distances from center to points on the perimeter\n",
    "- `texture_mean`: standard deviation of gray-scale values\n",
    "- `perimeter_mean`: mean size of the core tumor\n",
    "- `area_mean`: \n",
    "- `smoothness_mean`: mean of local variation in radius lengths\n",
    "- `compactness_mean`: mean of perimeter^2 / area - 1.0\n",
    "- `concavity_mean`: mean of severity of concave portions of the contour\n",
    "- `concave points_mean`: mean for number of concave portions of the contour\n",
    "- `symmetry_mean`: \n",
    "- `fractal_dimension_mean`: mean for \"coastline approximation\" - 1\n",
    "- `radius_se`: standard error for the mean of distances from center to points on the perimeter\n",
    "- `texture_se`: standard error for standard deviation of gray-scale values\n",
    "- `perimeter_se`: \n",
    "- `area_se`: \n",
    "- `smoothness_se`: standard error for local variation in radius lengths\n",
    "- `compactness_se`: standard error for perimeter^2 / area - 1.0\n",
    "- `concavity_se`: standard error for severity of concave portions of the contour\n",
    "- `concave points_se`: standard error for number of concave portions of the contour\n",
    "- `symmetry_se`: \n",
    "- `fractal_dimension_se`: standard error for \"coastline approximation\" - 1\n",
    "- `radius_worst`: \"worst\" or largest mean value for mean of distances from center to points on the perimeter\n",
    "- `texture_worst`: \"worst\" or largest mean value for standard deviation of gray-scale values\n",
    "- `perimeter_worst`: \n",
    "- `area_worst`: \n",
    "- `smoothness_worst`: \"worst\" or largest mean value for local variation in radius lengths\n",
    "- `compactness_worst`: \"worst\" or largest mean value for perimeter^2 / area - 1.0\n",
    "- `concavity_worst`: \"worst\" or largest mean value for severity of concave portions of the contour\n",
    "- `concave points_worst`: \"worst\" or largest mean value for number of concave portions of the contour\n",
    "- `symmetry_worst`: \n",
    "- `fractal_dimension_worst`: \"worst\" or largest mean value for \"coastline approximation\" - 1\n",
    "\n",
    "\n",
    "If we load this CSV data into a pandas dataframe, we can easily take a closer look\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"id\",\"diagnosis\",\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\n",
    "                \"compactness_mean\",\"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\n",
    "                \"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\n",
    "                \"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\n",
    "                \"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\"concavity_worst\",\n",
    "                \"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\"]\n",
    "breastcancer = pd.read_csv('./wdbc.data', header=None, names=col_names)\n",
    "breastcancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breast cancer dataset is quite small, with only 569 records, where each record uses 32 attributes to describe the profile of a breast mass.\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image\n",
    "\n",
    "Let's see which of our colums are of type string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breastcancer.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one column is of type string, and that is the diagnosis. Lets take a look at the diagnosis distribution in both absolute and normalised forms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.crosstab(index=breastcancer['diagnosis'], columns='% observations'))\n",
    "display(pd.crosstab(index=breastcancer['diagnosis'], columns='% observations', normalize='columns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 63% of our samples are benign and 37% are malignant. This is a reasonable spread\n",
    "\n",
    "Next we will take a closer look at all of the numeric features in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(breastcancer.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be more useful to look at the histograms of the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "hist = breastcancer.hist(bins=30, sharey=False, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these histograms we can see that:\n",
    "- Most of the numeric features are nicely distributed, with some even showing bell-like gaussianity.\n",
    "- `id` should not be included as a feature (and it should be converted to non-numeric) \n",
    "\n",
    "\n",
    "We will drop the `id` column from the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breastcancer = breastcancer.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note for future reference:\n",
    "There may be scenarios where you have a numeric field like `id` that did add some non-numeric value.\n",
    "A good example would be if the first N characters of patient ID indicated the country or state where the patient was located and you wanted to see if this location had any bearing on the diagnosis.\n",
    "In such a case you would convert the field to a string:\n",
    "<pre><code>breastcancer['id'] = breastcancer['id'].astype(object)</code></pre>\n",
    "and extract the pertinant information.\n",
    "You would then treat that field as a categorical field\n",
    "\n",
    "\n",
    "To take a look at the relationship between any categorical fields and the final diagnosis, you would use the following cross-tabulation report: \n",
    "<pre><code>for column in breastcancer.select_dtypes(include=['object']).columns:\n",
    "    if column != 'diagnosis':\n",
    "        display(pd.crosstab(index=breastcancer[column], columns=breastcancer['diagnosis'], normalize='columns'))\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will look at the direct relationship between numeric (non-object) values and diagnosis. We do this by plotting a histogram for every numeric value.\n",
    "We divide our samples into `bins`. The X-axis represents the bins and the Y-axis represents how many samples fall into each bin.\n",
    "By forcing the benign and malignant graphs to share the same X and Y scale it is easier to visualise which bins are more populated between the two diagnoses.\n",
    "\n",
    "Feel free to adjust the number of bins being plotted by the histogram and view the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for column in breastcancer.select_dtypes(exclude=['object']).columns:\n",
    "    print(column)\n",
    "    hist = breastcancer[[column, 'diagnosis']].hist(by='diagnosis', sharey=True, sharex=True, bins=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we infer from these relationships?\n",
    "\n",
    "We see that malignant diagnosis appear to have higher values for the following features:\n",
    "- radius_mean\n",
    "- perimeter_mean\n",
    "- area_mean\n",
    "- compactness_mean\n",
    "- concavity_mean\n",
    "- concave points_mean\n",
    "- radius_se\n",
    "- area_se\n",
    "- radius_worst\n",
    "- texture_worst\n",
    "- perimeter_worst\n",
    "- area_worst\n",
    "- compactness_worst\n",
    "- concavity_worst\n",
    "- concave points_worst\n",
    "\n",
    "We see similar distributions for features such as `radius_mean`, `perimeter_mean` and `area_mean` for both malignant and benign diagnosis. This makes sense as each of these features are related to the size of the tumour.\n",
    "\n",
    "Let's dig deeper into the relationships between our features by computing the pairwise correlation of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(breastcancer.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see several features that essentially have a strong (but not 100%) correlation with one another.\n",
    "\n",
    "One such example is radius_mean and perimeter_mean which have a correlation score of 0.997855\n",
    "\n",
    "It can be easier to see correlations using a scatter matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(breastcancer, figsize=(30, 30))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the scatter matrix, such strongly correlated features are indicated by a diagonal line running from bottom left to top right. In the correlation matrix, such relationships are indicated by a correlation value close to 1.\n",
    "\n",
    "In some cases it can be a good idea to remove one element of a highly correlated feature pair. \n",
    "For the first run of our training, I am going to leave all data in; however, it would be a valuable exercise to remove the following values and compare results of the final model:\n",
    "`perimeter_mean` and `area_mean` - since `radius_mean` has high correlation (>98%) with those measurements.\n",
    "A further exercise would be to remove one of a feature pair that have more than 96% correlation and compare final predictive results of the models. This is the 'scientific experimentation' side of data science.\n",
    "\n",
    "For reference, the command to drop columns from the pandas dataframe is:\n",
    "\n",
    "<pre><code>breastcancer = breastcancer.drop(['ColName1', 'ColName2'], axis=1)</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a clean dataset (and have potentially removed some unneccessary columns), we can prepare the dataset for XGBoost. \n",
    "\n",
    "Amazon SageMaker XGBoost can train on data in either a CSV or LibSVM format.  For this example, we'll stick with CSV.  It should:\n",
    "- Contain only numeric values\n",
    "- Have the predictor variable in the first column\n",
    "- Not have a header row\n",
    "\n",
    "We will also\n",
    "- Shuffle the dataset\n",
    "- Split the dataset into training, validation and testing sets\n",
    "\n",
    "### Step 1: Convert our categorical features into numeric features using the \"get_dummies\" function which will automatically convert categorical variable into dummy/indicator variables.\n",
    "\n",
    "I have shown the first and last row of the dataset in order to illustrate the output of the 'get_dummies' method.\n",
    "\n",
    "Since our only categorical variable is 'diagnosis', you will see that it now appears as the last column(s) of the new dataset broken up into one column per diagnosis label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 3)\n",
    "display(breastcancer)\n",
    "model_data = pd.get_dummies(breastcancer)\n",
    "display(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Select a single predictor variable and bring it forward to the first column\n",
    "\n",
    "Now we will keep only one of the predictor variables `diagnosis_M` which is our label for the tumour being malignant. We will append this column to a version of our dataset that drops the predictor columns (as XGBoost requires the predictor variable as the first column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.concat([model_data['diagnosis_M'], model_data.drop(['diagnosis_B', 'diagnosis_M'], axis=1)], axis=1)\n",
    "display(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's split the data into training, validation, and test sets.  This will help prevent us from overfitting the model, and allow us to test the models accuracy on data it hasn't already seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: Shuffle the input dataset\n",
    "\n",
    "We will shuffle the order of the dataset so as to reduce variance and ensure that the resultant model remains general.\n",
    "\n",
    "We do this with the `sample` method.\n",
    "I am specifying a value for `random state` only for the purposes of reproducability\n",
    "Setting `frac`=1 specifies to keep all the samples, as opposed to returning a fraction of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data=model_data.sample(frac=1, random_state=1)\n",
    "display(shuffled_data)\n",
    "pd.reset_option('max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split the dataset\n",
    "\n",
    "Split our data into a training dataset, validation dataset and test dataset.\n",
    "\n",
    "The ratio we will use is:\n",
    "- Training dataset - 70%\n",
    "- Validation dataset - 20%\n",
    "- Test dataset - 10%\n",
    "\n",
    "We do this using the numpy `split` function specifying splits at the 70% mark and the 90% mark of the shuffled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = np.split(shuffled_data, [int(0.7 * len(model_data)), int(0.9 * len(model_data))])\n",
    "print(\"Training data sample size:\",len(train_data))\n",
    "print(\"Validation data sample size:\",len(validation_data))\n",
    "print(\"Test data sample size:\",len(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the training dataset and validation dataset to CSV and upload to S3 for consumption by the containers running the XGBoost algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload these files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train\n",
    "\n",
    "Moving onto training, first we'll need to specify the locations of the XGBoost algorithm containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, because we're training with the CSV file format, we'll create `s3_input`s that our training function can use as a pointer to the files in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can specify a few parameters like what type of training instances we'd like to use and how many, as well as our XGBoost hyperparameters.  A few key hyperparameters are:\n",
    "- `max_depth` controls how deep each tree within the algorithm can be built.  Deeper trees can lead to better fit, but are more computationally expensive and can lead to overfitting.  There is typically some trade-off in model performance that needs to be explored between a large number of shallow trees and a smaller number of deeper trees.\n",
    "- `subsample` controls sampling of the training data.  This technique can help reduce overfitting, but setting it too low can also starve the model of data.\n",
    "- `num_round` controls the number of boosting rounds.  This is essentially the subsequent models that are trained using the residuals of previous iterations.  Again, more rounds should produce a better fit on the training data, but can be computationally expensive or lead to overfitting.\n",
    "- `eta` controls how aggressive each round of boosting is.  Larger values lead to more conservative boosting.\n",
    "- `gamma` controls how aggressively trees are grown.  Larger values lead to more conservative models.\n",
    "\n",
    "More detail on XGBoost's hyperparmeters can be found on the GitHub [page](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.1,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Hosting\n",
    "Now that we've trained the `xgboost` algorithm on our data, let's deploy a model that's hosted behind a real-time endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Now that we have a hosted endpoint running, we can make real-time predictions from our model very easily, simply by making an http POST request.  But first, we'll need to setup serializers and deserializers for passing our `test_data` NumPy arrays to the model behind the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "xgb_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a simple function to:\n",
    "1. Loop over our test dataset\n",
    "1. Extract the features for each sample \n",
    "1. Retrieve the prediction for each sample by invoking the XGBoost endpoint\n",
    "1. Collect predictions and convert from a python list to a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a numpy array\n",
    "dtest = test_data.to_numpy()\n",
    "\n",
    "# As expected, the numpy array has 57 rows (57 samples in the test dataset), and 31 columns (30 features + 1 label)\n",
    "#print(dtest.shape)\n",
    "\n",
    "# Create a list to hold all of our predictions\n",
    "predictions = []\n",
    "\n",
    "# Loop through the matrix of our test data samples, pulling out the features for each sample and running inference\n",
    "# Note: dtest[i:i+1, 1:] is an vector of all the features for the sample i (without the first entry which is the label)\n",
    "for i in range(dtest.shape[0]):\n",
    "    sample_features=dtest[i:i+1, 1:]\n",
    "    prediction=xgb_predictor.predict(sample_features).decode('utf-8')\n",
    "    predictions.append(float(prediction))\n",
    "       \n",
    "# Convert our list of predictions to a numpy array\n",
    "predictions = np.asarray(predictions)\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of this machine learning model on the test dataset, we will use a simple confusion matrix to compare actual to predicted values.  In this case, we're predicting whether the tumor was malignant (`1`) or benign (`0`).\n",
    "\n",
    "- We get the actual values from the first column (column 0) of the dataset: `test_data.iloc[:, 0]`\n",
    "- We get the predicted values from our array of predictions: `predictions`. We will simply round the predictions to the nearest integer (so a prediction < 0.5 will be 0 - benign and a prediction => 0.5 will be 1 - malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=test_data.iloc[:, 0], columns=np.round(predictions), rownames=['actual'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 57 samples in the test dataset, 34 were for benign tumours and indeed we've correctly predicted all 34 of them.\n",
    "23 of the samples were malignant and we correctly predicted 20 of them.\n",
    "3 of of the malignant samples were incorrectly predicted as benign\n",
    "\n",
    "An important point here is that because of the `np.round()` function above we are using a simple threshold (or cutoff) of 0.5.  Our predictions from `xgboost` come out as continuous values between 0 and 1 and we force them into the binary classes that we began with.  \n",
    "\n",
    "However, because we would rather err on the side of a false positive than a false negative, we will adjust this cutoff. \n",
    "\n",
    "To get a rough intuition here, let's look at the continuous values of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predictions, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The continuous valued predictions coming from our model are generally quite decisive so tend to skew toward 0 or 1; however there are a few values between 0.1 and 0.9 where the model is less confident.\n",
    "\n",
    "How you adjust the cutoff is completely dependent upon the problem space you are addressing and whether you want to have more likelihood of false positives or false negatives.\n",
    "\n",
    "In the case of predicting malignant tumours we will be somewhat conservative and report any prediction greater than 0.3 as malignant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=test_data.iloc[:, 0], columns=np.where(predictions > 0.3, 1, 0), rownames=['actual'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that changing the cutoff from 0.5 to 0.3 yields improved results. \n",
    "\n",
    "There is still 1 malignant sample that is being incorrectly predicted as benign. This would certainly require further investigation, hyperparameter tuning and likely even an ensemble approach where the prediction from this model are combined with the predictions of other models in order to vote for the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extensions\n",
    "\n",
    "### Hyperparameter-Optimization\n",
    "\n",
    "Set our static hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_hyperparameters = {\n",
    "    \"objective\" : \"binary:logistic\",\n",
    "    \"num_round\" : \"100\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "container = get_image_uri(region, 'xgboost', repo_version='latest')\n",
    "\n",
    "xgb_hpo = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "xgb_hpo.set_hyperparameters(**static_hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set our hyperparameters that we want SageMaker to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_hyperparameter_ranges = {'eta': ContinuousParameter(0.1, 0.5),\n",
    "                        'min_child_weight': ContinuousParameter(1, 10),\n",
    "                        'alpha': ContinuousParameter(0, 2),\n",
    "                        #'gamma': ContinuousParameter(0, 20),\n",
    "                        'subsample': ContinuousParameter(0.5, 1),\n",
    "                        'max_depth': IntegerParameter(6, 10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(xgb_hpo,\n",
    "                            objective_metric_name='validation:error',\n",
    "                            objective_type='Minimize',\n",
    "                            hyperparameter_ranges=tuned_hyperparameter_ranges,\n",
    "                            max_jobs=20,\n",
    "                            max_parallel_jobs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime('-%Y%m%d%H%M', time.gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit({'train': s3_input_train, 'validation': s3_input_validation}, job_name='HPObreastCancer'+timestamp, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check job name and status of HPO job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_client = boto3.Session().client('sagemaker')\n",
    "\n",
    "hpo_job_name=tuner.latest_tuning_job.job_name\n",
    "print(hpo_job_name)\n",
    "\n",
    "sage_client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=hpo_job_name)['HyperParameterTuningJobStatus']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze tuning job results - after tuning job is completed\n",
    "Please refer to \"HPO_Analyze_TuningJob_Results.ipynb\" to see example code to analyze the tuning job results.\n",
    "\n",
    "If the job is complete and you really don't care about analysing the results, the code below will return you the best job name and the best combination of hyperparameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_result = sage_client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=hpo_job_name)\n",
    "best_job=tuning_job_result.get('BestTrainingJob',None)\n",
    "\n",
    "best_job_name=best_job.get('TrainingJobName',None)\n",
    "tuned_hyperparams=best_job.get('TunedHyperParameters',None)\n",
    "print(\"Best job had name:\",best_job_name)\n",
    "print(\"Best hyperparameter combination:\",tuned_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a hosted endpoint from the best job results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate the S3 path to the model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = sage_client.describe_training_job(TrainingJobName=best_job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a SageMaker model from the model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "model_name=best_job_name + '-model'\n",
    "\n",
    "create_model_response = sage_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a configuration for a SageMaker hosted endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = 'HPO-XGBoostEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sage_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.t2.medium',\n",
    "        'InitialVariantWeight':1,\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a SageMaker hosted endpoint using the configuration created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'HPO-XGBoostEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = sage_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sage_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    resp = sage_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a predictor (this is an object to make it simpler to make requests to an endpoint). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor_hpo=sagemaker.predictor.RealTimePredictor(endpoint=endpoint_name,\n",
    "                               serializer=csv_serializer,\n",
    "                               deserializer=None,\n",
    "                               content_type='text/csv',\n",
    "                               accept=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is the same as the code we used to run our test data against our initial predictor (before hyperparameter optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold all of our predictions using the HPO model\n",
    "predictions_hpo = []\n",
    "\n",
    "# Loop through the matrix of our test data samples, pulling out the features for each sample and running inference\n",
    "# Note: dtest[i:i+1, 1:] is an vector of all the features for the sample i (without the first entry which is the label)\n",
    "for i in range(dtest.shape[0]):\n",
    "    sample_features=dtest[i:i+1, 1:]\n",
    "    prediction=xgb_predictor_hpo.predict(sample_features).decode('utf-8')\n",
    "    predictions_hpo.append(float(prediction))\n",
    "       \n",
    "# Convert our list of predictions to a numpy array\n",
    "predictions_hpo = np.asarray(predictions_hpo)\n",
    "display(predictions_hpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does our new model go at making predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=test_data.iloc[:, 0], columns=np.round(predictions_hpo), rownames=['actual'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly it only has 2 false negatives where the original model had 3.\n",
    "What about if we shift the cutoff point for a positive result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=test_data.iloc[:, 0], columns=np.where(predictions_hpo > 0.3, 1, 0), rownames=['actual'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is no better than our result before Hyperparameter Optimization.\n",
    "At this point we can't improve our model any further, so we know we need to look at the data. \n",
    "Perhaps we need to use domain knowledge to include extra relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Clean-up\n",
    "\n",
    "If you're finished with this notebook, please run the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "sagemaker.Session().delete_endpoint(xgb_predictor_hpo.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
